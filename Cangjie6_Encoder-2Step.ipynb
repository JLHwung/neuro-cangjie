{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from fontTools.ttLib import TTFont\n",
    "from macrotoolchain import Data, Graph, plot \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Glyph(object):\n",
    "    # transform character to bitmap\n",
    "    def __init__(self, fonts, size=64):\n",
    "        # load fonts, size. We will use 2 fonts for all CJK characters, so keep 2 codepoint books.\n",
    "        self.codepoints = [set()] * len(fonts)\n",
    "        self.size = int(size * 0.8)\n",
    "        self.size_img = size\n",
    "        self.pad = (size - self.size) // 2\n",
    "        self.fonts = [ImageFont.truetype(f, self.size) for f in fonts]\n",
    "        # use a cache to reduce computation if duplicated characters encountered.\n",
    "        self.cache = {}\n",
    "        for cp, font in zip(self.codepoints, fonts):\n",
    "            font = TTFont(font)\n",
    "            # store codepoints in font cmap into self.codepoints\n",
    "            for cmap in font['cmap'].tables:\n",
    "                if not cmap.isUnicode():\n",
    "                    continue\n",
    "                for k in cmap.cmap:\n",
    "                    cp.add(k)\n",
    "    \n",
    "    def draw(self, ch):\n",
    "        if ch in self.cache:\n",
    "            return self.cache[ch]\n",
    "        # search among fonts, use the first found\n",
    "        exist = False\n",
    "        for i in range(len(self.codepoints)):\n",
    "            if ord(ch) in self.codepoints[i]:\n",
    "                font = self.fonts[i]\n",
    "                exist = True\n",
    "                break\n",
    "        if not exist:\n",
    "            return None\n",
    "\n",
    "        img = Image.new('L', (self.size_img, self.size_img), 0)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        (width, baseline), (offset_x, offset_y) = font.font.getsize(ch)\n",
    "        draw.text((self.pad - offset_x, self.pad - offset_y + 4), ch, font=font, fill=255, stroke_fill=255) \n",
    "        img_array = np.array(img.getdata(), dtype='float32').reshape((self.size_img, self.size_img)) / 255\n",
    "        self.cache[ch] = img_array\n",
    "\n",
    "        return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glyphbook = Glyph(['data/fonts/HanaMinA.otf', 'data/fonts/HanaMinB.otf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_chart = pd.read_csv('data/cangjie6.txt', delimiter='\\t', header=None, names=['Char', 'Code'], \n",
    "                        keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_chart(chart):\n",
    "    glyphs = []\n",
    "    codes = []\n",
    "    for char, code in chart.values:\n",
    "        glyph = glyphbook.draw(char)\n",
    "        if glyph is not None:\n",
    "            glyphs.append(glyph)\n",
    "            codes.append(code)\n",
    "    return np.expand_dims(np.array(glyphs), -1), np.array(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = 28\n",
    "def tokenizer(code_table):\n",
    "    # Cangjie code consists only of a-z, with maximum length of 5, minimum of 1\n",
    "    # start with 0, a-z are 1-26, end and padding are 27\n",
    "    tokens = np.expand_dims(np.zeros(code_table.shape, dtype='int64'), -1)\n",
    "    code_index = list(map(lambda x: list(map(lambda y: ord(y) - 96, list(x))) + [27] * (5-len(x)), code_table))\n",
    "    tokens = np.append(tokens, np.array(code_index), axis=-1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "glyphs, codes = preprocess_chart(code_chart)\n",
    "tokens = tokenizer(codes)\n",
    "lengths = np.array([len(list(filter(lambda i: i < 27 and i > 0, x))) for x in tokens])\n",
    "lengths = np.array([np.identity(5)[i-1] for i in lengths], dtype='int64')\n",
    "del code_chart, codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_glyphs, validation_glyphs, train_tokens, validation_tokens, train_lengths, validation_lengths = \\\n",
    "train_test_split(glyphs, tokens, lengths, test_size=0.1)\n",
    "del glyphs, tokens, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_glyphs, train_tokens, train_lengths))\n",
    "dataset = dataset.shuffle(train_glyphs.shape[0]).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res_CNN(tf.keras.Model):\n",
    "    def __init__(self, feature_dim, kernel_size):\n",
    "        super(Res_CNN, self).__init__()\n",
    "        self.cnn1 = tf.keras.layers.Convolution2D(feature_dim, kernel_size)\n",
    "        self.cnn2 = tf.keras.layers.Convolution2D(feature_dim, kernel_size, padding='same')\n",
    "        self.cnn3 = tf.keras.layers.Convolution2D(feature_dim, kernel_size, padding='same')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x_identity = tf.identity(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = self.cnn3(x)\n",
    "        x = tf.nn.relu(x + x_identity)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Encoder(tf.keras.Model):\n",
    "    # This is essentially a CNN layer, \n",
    "    def __init__(self, embedding_dim):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        self.res_cnn1 = Res_CNN(embedding_dim // 16, (3, 3))\n",
    "        self.norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "        self.res_cnn2 = Res_CNN(embedding_dim // 4, (3, 3))\n",
    "        self.norm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "        self.res_cnn3 = Res_CNN(embedding_dim, (3, 3))\n",
    "        self.norm3 = tf.keras.layers.BatchNormalization()\n",
    "        self.fc = tf.keras.layers.Dense(embedding_dim, activation='relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        # x shape after cnn1 == (batch_size, 62, 62, embedding_dim // 16)\n",
    "        x = self.res_cnn1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        # x shape after pool1 == (batch_size, 31, 31, embedding_dim // 16)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # x shape after cnn2 == (batch_size, 29, 29, embedding_dim // 4)\n",
    "        x = self.res_cnn2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        # x shape after pool2 == (batch_size, 14, 14, embedding_dim // 4)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # x shape after cnn3 == (batch_size, 12, 12, embedding_dim)\n",
    "        x = self.res_cnn3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        # reshape from (batch_size, 12, 12, 128) to (batch_size, 144, embedding_dim)\n",
    "        x = tf.reshape(x, [x.shape[0], -1, x.shape[-1]])\n",
    "        # x shape after fc == (batch_size, 144, embedding_dim)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bahdanau_Attention(tf.keras.Model):\n",
    "    def __init__(self, attention_dim):\n",
    "        super(Bahdanau_Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(attention_dim)\n",
    "        self.W2 = tf.keras.layers.Dense(attention_dim)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        # features(CNN_Encoder output) shape == (batch_size, 36, embedding_dim)\n",
    "\n",
    "        # hidden shape == (batch_size, hidden_size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        # score shape == (batch_size, 81, attention_dim)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "\n",
    "        # attention_weights shape == (batch_size, 36, 1)\n",
    "        # you get 1 at the last axis because you are applying score to self.V\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, embedding_dim)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, max_length, hidden_size, vocab_size):\n",
    "        super(Simple_Decoder, self).__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.attention = Bahdanau_Attention(hidden_size)\n",
    "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, feature, position):\n",
    "        # y shape (batch_size, hidden_size)\n",
    "        y = self.embedding(position)\n",
    "        # x shape (batch_size, embedding_dim)\n",
    "        x, w = self.attention(feature, y)\n",
    "        # x shape (batch_size, hidden_size)\n",
    "        x = self.fc1(x)\n",
    "        # x shape (batch_size, vocab_size)\n",
    "        x = self.fc2(x)\n",
    "        return x, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Length_Decoder(tf.keras.Model):\n",
    "    def __init__(self, max_length):\n",
    "        super(Length_Decoder, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(max_length * 16, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(max_length * 4, activation='relu')\n",
    "        self.fc3 = tf.keras.layers.Dense(max_length)\n",
    "        \n",
    "    def call(self, feature):\n",
    "        x = tf.reshape(feature, (feature.shape[0], -1))\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        # shape = (batch_size, max_length)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, hidden_size, vocab_size, max_length):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru1 = tf.keras.layers.GRU(self.hidden_size, return_sequences=True,\n",
    "                                        return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        self.gru2 = tf.keras.layers.GRU(self.hidden_size, return_sequences=True,\n",
    "                                        return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        self.gru3 = tf.keras.layers.GRU(self.hidden_size, return_sequences=True,\n",
    "                                        return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = Bahdanau_Attention(hidden_size)\n",
    "\n",
    "    def call(self, x, l, features, hidden):\n",
    "        # x is forward direction, y is beckward direction\n",
    "        # defining attention as a separate model\n",
    "        context_vector, attention_weights = self.attention(features, hidden[0])\n",
    "        l = tf.expand_dims(tf.cast(l, 'float32'), 1)\n",
    "\n",
    "        # x shape before is (batch_size, 1) since it is passed through one by one at a time\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # context_vector shape is (batch_size, embedding_dim)\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + embedding_dim)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        # x shape is (batch_size, 1, hidden_size)\n",
    "        # state is new hidden used in next step\n",
    "        x, state1 = self.gru1(x, initial_state = hidden[0])\n",
    "        x_identity = tf.identity(x)\n",
    "        x = tf.concat([l, x], axis=-1)\n",
    "        x, state2 = self.gru2(x, initial_state = hidden[1])\n",
    "        x_identity2 = tf.identity(x)\n",
    "        x, state3 = self.gru3(x + x_identity, initial_state = hidden[2])\n",
    "        # x shape (batch_size, 1, max_length + hidden_size)\n",
    "        x = tf.concat([l, x + x_identity2], axis=-1)\n",
    "        x = tf.reshape(x, (x.shape[0], -1))\n",
    "        # x shape (batch_size, hidden_size)\n",
    "        x = self.fc1(x)\n",
    "        # x shape (batch_size, vocab_size)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, [state1, state2, state3], attention_weights\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        # generate new hidden layer with different batch size\n",
    "        return [tf.zeros((batch_size, self.hidden_size))] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_step1 = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    loss_ = loss_object(real, pred)\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    pred_index = tf.math.argmax(pred, axis=-1)\n",
    "    return tf.math.reduce_mean(tf.cast(pred_index == real, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step1(glyph, target):\n",
    "    loss = 0; accuracy = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        feature = encoder(glyph)\n",
    "        for i in range(1, target.shape[1]):\n",
    "            position = tf.convert_to_tensor(np.repeat(i-1, target.shape[0]), dtype='int64')\n",
    "            prediction, weight = decoder_step1(feature, position)\n",
    "            loss += tf.reduce_mean(loss_object(target[:, i], prediction))\n",
    "            accuracy += accuracy_function(target[:, i], prediction)\n",
    "    trainable_variables = decoder_step1.trainable_variables + encoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    optimizer_step1.apply_gradients(zip(gradients, trainable_variables))\n",
    "    return loss / (target.shape[1] - 1), accuracy / (target.shape[1] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def validation_step1(glyph, target):\n",
    "    loss = 0; accuracy = 0\n",
    "    feature = encoder(glyph)\n",
    "    for i in range(1, target.shape[1]):\n",
    "        position = tf.convert_to_tensor(np.repeat(i-1, target.shape[0]), dtype='int64')\n",
    "        prediction, weight = decoder_step1(feature, position)\n",
    "        loss += tf.reduce_mean(loss_object(target[:, i], prediction))\n",
    "        accuracy += accuracy_function(target[:, i], prediction)\n",
    "    return loss / (target.shape[1] - 1), accuracy / (target.shape[1] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def step1(epoch):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    for (batch, (glyph_tensor, target, length)) in enumerate(dataset):\n",
    "        t_loss, accuracy = train_step1(glyph_tensor, target)\n",
    "        total_loss += t_loss\n",
    "        total_accuracy += accuracy\n",
    "        print(f'Epoch {epoch + 1}, Train Loss {total_loss/batch:.6f}, Accuracy {total_accuracy / batch:.2%};\\\n",
    " progression {batch / num_steps:.1%}, time elapsed {time.time() - start:.2f} sec', end='\\r')\n",
    "    \n",
    "    val_loss, val_accuracy = validation_step1(validation_glyphs, validation_tokens)\n",
    "   \n",
    "    # storing the epoch end loss value to plot later \n",
    "    ckpt_manager_step1.save()\n",
    "\n",
    "    print (f'Epoch {epoch+1}, Train Loss {total_loss/num_steps:.6f}, Accuracy {total_accuracy/num_steps:.2%};\\\n",
    " Validation Loss {val_loss:.6f}, Accuracy {val_accuracy:.2%}; taken {time.time() - start:.2f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def predict(features, max_length):\n",
    "    # start with 0\n",
    "    dec_input = tf.convert_to_tensor([[0]]*features.shape[0], dtype='int64')\n",
    "    hidden = decoder.reset_state(batch_size=features.shape[0])\n",
    "    length = tf.nn.softmax(length_decoder(features), axis=-1)\n",
    "    # iterate predictions, no teacher forcing here\n",
    "    for i in range(max_length):\n",
    "        prediction, hidden, attention_weights = decoder(tf.expand_dims(dec_input[:, i], 1), length, features, hidden)\n",
    "        # we need deterministic result\n",
    "        predicted_id = tf.math.argmax(prediction, axis=-1)\n",
    "        dec_input = tf.concat([dec_input, tf.expand_dims(predicted_id, 1)], axis=1)\n",
    "    return dec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def predict_next(features, target, length):\n",
    "    hidden = decoder.reset_state(batch_size=features.shape[0])\n",
    "    predictions = tf.constant(0, dtype='float32', shape=(features.shape[0], 1, VOCAB))\n",
    "    for i in range(target.shape[1]-1):\n",
    "        prediction, hidden, attention_weights = decoder(tf.expand_dims(target[:, i], 1), length, features, hidden)\n",
    "        predictions = tf.concat([predictions, tf.expand_dims(prediction, 1)], axis=1)\n",
    "    return predictions[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_step2 = tf.keras.optimizers.Adam()\n",
    "optimizer_length = tf.keras.optimizers.Adam()\n",
    "\n",
    "def loss_function_step2(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    loss_ = tf.reduce_mean(loss_, axis=0)\n",
    "    return tf.reduce_sum(loss_)\n",
    "\n",
    "def accuracy_function_step2(real, pred):\n",
    "    accuracy = tf.math.reduce_all(pred == real, 1)\n",
    "    return tf.math.reduce_mean(tf.cast(accuracy, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step2(glyph_tensor, target, length, rnn_only=False):\n",
    "    # use tape to auto generate gradients\n",
    "    if rnn_only:\n",
    "        features = encoder(glyph_tensor)\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = predict_next(features, target, length)\n",
    "            loss = loss_function_step2(target[:, 1:], predictions)\n",
    "    else:\n",
    "        with tf.GradientTape() as tape:\n",
    "            features = encoder(glyph_tensor)\n",
    "            predictions = predict_next(features, target, length)\n",
    "            loss = loss_function_step2(target[:, 1:], predictions)\n",
    "    with tf.GradientTape() as tape_length:\n",
    "        length_pred = length_decoder(features)\n",
    "        loss_length = loss_function(tf.math.argmax(length, axis=-1), length_pred)\n",
    "    # calculate accuracy based on the code's whole string\n",
    "    predictions_id = predict(features, target.shape[1]-1)\n",
    "    accuracy = accuracy_function_step2(predictions_id, target)\n",
    "\n",
    "    trainable_variables = decoder.trainable_variables\n",
    "    if not rnn_only:\n",
    "        trainable_variables += encoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    optimizer_step2.apply_gradients(zip(gradients, trainable_variables))\n",
    "    gradients_length = tape_length.gradient(loss_length, length_decoder.trainable_variables)\n",
    "    optimizer_length.apply_gradients(zip(gradients_length, length_decoder.trainable_variables))\n",
    "\n",
    "    return loss / (target.shape[1] - 1), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def validation_step2(glyph_tensor, target, length):\n",
    "    features = encoder(glyph_tensor)\n",
    "    predictions = predict_next(features, target, length)\n",
    "    loss = loss_function_step2(target[:, 1:], predictions)\n",
    "    \n",
    "    # calculate accuracy based on the code's whole string\n",
    "    predictions_id = predict(features, target.shape[1]-1)\n",
    "    accuracy = accuracy_function_step2(predictions_id, target)\n",
    "    \n",
    "    return loss / (target.shape[1] - 1), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "graph_log_dir = 'logs/gradient_tape/' + current_time + '/func'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "graph_summary_writer = tf.summary.create_file_writer(graph_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def step2(epoch, rnn_only=False):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    for (batch, (glyph_tensor, target, length)) in enumerate(dataset):\n",
    "        if batch == 0:\n",
    "            tf.summary.trace_on(graph=True, profiler=True)\n",
    "        t_loss, accuracy = train_step2(glyph_tensor, target, length, rnn_only=rnn_only)\n",
    "        if batch == 0:\n",
    "            with graph_summary_writer.as_default():\n",
    "                tf.summary.trace_export(name=\"train_trace\", step=epoch, profiler_outdir=graph_log_dir)\n",
    "            tf.summary.trace_off()\n",
    "        total_loss += t_loss\n",
    "        total_accuracy += accuracy\n",
    "        print(f'Epoch {epoch + 1}, Train Loss {total_loss/batch:.6f}, Accuracy {total_accuracy/batch:.2%};\\\n",
    " progression {batch / num_steps:.1%}, time elapsed {time.time() - start:.2f} sec', end='\\r')\n",
    "    \n",
    "    val_loss, val_accuracy = validation_step2(validation_glyphs, validation_tokens, validation_lengths)\n",
    "   \n",
    "    # storing the epoch end loss value to plot later\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', (total_loss / num_steps), step=epoch)\n",
    "        tf.summary.scalar('accuracy', (total_accuracy / num_steps), step=epoch)\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', val_loss, step=epoch)\n",
    "        tf.summary.scalar('accuracy', val_accuracy, step=epoch)\n",
    "    \n",
    "    ckpt_manager_step2.save()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Train Loss {total_loss/num_steps:.6f},\\\n",
    " Accuracy {total_accuracy / num_steps:.2%}; Validation Loss {val_loss:.6f},\\\n",
    " Accuracy {val_accuracy:.2%}; taken {time.time() - start:.2f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim = 128)\n",
    "decoder_step1 = Simple_Decoder(embedding_dim = 128, max_length = train_tokens.shape[1]-1,\n",
    "                              hidden_size = 128, vocab_size = VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_decoder = Length_Decoder(max_length = train_lengths.shape[1])\n",
    "decoder = RNN_Decoder(embedding_dim=128, hidden_size=128, max_length = train_lengths.shape[1], vocab_size=VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a checkpoint to store weights\n",
    "checkpoint_path_step1 = './checkpoints/train_step1'\n",
    "ckpt_step1 = tf.train.Checkpoint(encoder=encoder, decoder=decoder_step1, optimizer=optimizer_step1)\n",
    "ckpt_manager_step1 = tf.train.CheckpointManager(ckpt_step1, checkpoint_path_step1, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a checkpoint to store weights\n",
    "checkpoint_path_step2 = \"./checkpoints/train_step2\"\n",
    "ckpt_step2 = tf.train.Checkpoint(encoder=encoder, decoder=decoder, optimizer=optimizer_step2)\n",
    "ckpt_manager_step2 = tf.train.CheckpointManager(ckpt_step2, checkpoint_path_step2, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_step1 = 2\n",
    "num_steps = len(train_glyphs) // BATCH_SIZE\n",
    "\n",
    "epoch_step1 = 0\n",
    "if ckpt_manager_step1.latest_checkpoint:\n",
    "    epoch_step1 = int(ckpt_manager_step1.latest_checkpoint.split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "while epoch_step1 < EPOCHS_step1:\n",
    "    step1(epoch_step1)\n",
    "    epoch_step1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_step2 = 2\n",
    "\n",
    "epoch_step2 = 0\n",
    "if ckpt_manager_step2.latest_checkpoint:\n",
    "    epoch_step2 = int(ckpt_manager_step2.latest_checkpoint.split('-')[-1])\n",
    "    ckpt_step2.restore(ckpt_manager_step2.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trace already enabled\n",
      "Epoch 1, Train Loss 2.363764, Accuracy 1.21%; Validation Loss 2.087896, Accuracy 3.60%; taken 806.14 sec\n",
      "Epoch 2, Train Loss 2.027169, Accuracy 6.42%; Validation Loss 1.957568, Accuracy 9.30%; taken 768.48 sec\n"
     ]
    }
   ],
   "source": [
    "while epoch_step2 < EPOCHS_step2:\n",
    "    step2(epoch_step2)\n",
    "    epoch_step2 += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(word):\n",
    "    test_input = []\n",
    "    for char in word:\n",
    "        glyph = glyphbook.draw(char)\n",
    "        if glyph is not None:\n",
    "            test_input.append(glyph)\n",
    "        else:\n",
    "            raise ValueError(f'Character {char} unsupported.')\n",
    "    test_input = tf.expand_dims(test_input, -1)\n",
    "    features = encoder(test_input)\n",
    "    test_result = predict(features, 5)\n",
    "\n",
    "    def decode(indexes):\n",
    "        code = ''\n",
    "        for i in indexes:\n",
    "            if i <= 0:\n",
    "                continue\n",
    "            elif i >= 27:\n",
    "                break\n",
    "            else:\n",
    "                code += chr(i + 96)\n",
    "        return code\n",
    "\n",
    "    return np.apply_along_axis(decode, 1, test_result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ls', 'wl'], dtype='<U2')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('中國')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
